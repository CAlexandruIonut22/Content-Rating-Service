# app/llm_module/factuality_checker.py - Optimizat pentru TinyLlama-1.1B

import sys
import os
import time
import json
import re
import logging

# Fix pentru import-uri
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

from .model_handler import ModelHandler

try:
    from .web_search_agent import WebSearchAgent
except ImportError:
    WebSearchAgent = None
    
try:
    from app.config import Config
except ImportError:
    # Fallback config pentru TinyLlama
    class Config:
        LLM_MODEL_ID = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
        USE_WEB_SEARCH = True
        TAVILY_API_KEY = os.environ.get('TAVILY_API_KEY', None)
        USE_HYBRID_ANALYSIS = False
        MAX_WEB_SEARCHES = 3
        MAX_TEXT_LENGTH_FOR_ANALYSIS = 1500
        TINYLLAMA_PROMPT_MAX_LENGTH = 800
        TINYLLAMA_USE_SIMPLE_PROMPTS = True

logger = logging.getLogger(__name__)

class FactualityChecker:
    """
    Analizor factualitate optimizat pentru TinyLlama-1.1B
    Focus pe prompturi simple »ôi analizƒÉ rapidƒÉ
    """
    
    def __init__(self):
        """Ini»õializeazƒÉ checker-ul pentru TinyLlama"""
        self.model_handler = ModelHandler()
        self.web_search_agent = None
        
        # Ini»õializeazƒÉ TinyLlama
        if not self.model_handler.initialized:
            logger.info("Ini»õializez TinyLlama pentru analizƒÉ factualitate...")
            try:
                self.model_handler.initialize(
                    model_id=getattr(Config, 'LLM_MODEL_ID', 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'),
                    cache_dir=getattr(Config, 'LLM_CACHE_DIR', './model_cache'),
                    hf_token=getattr(Config, 'HUGGINGFACE_TOKEN', None)
                )
                logger.info("‚úÖ TinyLlama ini»õializat pentru analizƒÉ!")
            except Exception as e:
                logger.error(f"‚ùå Eroare ini»õializare TinyLlama: {e}")
                raise
        
        # Ini»õializeazƒÉ web search dacƒÉ e disponibil
        if (getattr(Config, 'USE_WEB_SEARCH', False) and 
            getattr(Config, 'TAVILY_API_KEY', None) and 
            WebSearchAgent):
            try:
                self.web_search_agent = WebSearchAgent(Config.TAVILY_API_KEY)
                logger.info("‚úÖ Tavily Web Search activat pentru TinyLlama!")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Web search e»ôuat: {e}")
                self.web_search_agent = None
        else:
            logger.info("‚ÑπÔ∏è  Web search dezactivat")
    
    def analyze_text_content(self, text, title=None):
        """
        AnalizƒÉ factualitate optimizatƒÉ pentru TinyLlama
        """
        if not text or len(text.strip()) < 10:
            return {
                "factuality_score": 0,
                "confidence": 0,
                "reasoning": "Text prea scurt pentru analizƒÉ.",
                "questionable_claims": [],
                "analysis_type": "insufficient_content"
            }
        
        # PregƒÉte»ôte textul pentru TinyLlama
        analyzed_text = self._prepare_text_for_tinyllama(text)
        
        if not analyzed_text:
            return {
                "factuality_score": 0,
                "confidence": 0,
                "reasoning": "Nu s-a putut procesa textul.",
                "questionable_claims": [],
                "analysis_type": "processing_error"
            }
        
        try:
            # Decidem tipul de analizƒÉ
            if (self.web_search_agent and 
                getattr(Config, 'USE_HYBRID_ANALYSIS', True)):
                logger.info("üîç AnalizƒÉ hibridƒÉ: TinyLlama + Web Search")
                return self._hybrid_analysis_tinyllama(analyzed_text, title)
            else:
                logger.info("ü§ñ AnalizƒÉ doar cu TinyLlama")
                return self._tinyllama_only_analysis(analyzed_text, title)
                
        except Exception as e:
            logger.error(f"Eroare analizƒÉ factualitate: {e}")
            return {
                "factuality_score": 5,
                "confidence": 3,
                "reasoning": f"Eroare la procesare cu TinyLlama: {str(e)[:100]}...",
                "questionable_claims": [],
                "analysis_type": "error"
            }
    
    def _prepare_text_for_tinyllama(self, text):
        """PregƒÉte»ôte text pentru TinyLlama (limitƒÉri mai stricte)"""
        if not text:
            return ""
        
        # CurƒÉ»õƒÉ textul
        cleaned_text = re.sub(r'\s+', ' ', text.strip())
        
        # Limitare strictƒÉ pentru TinyLlama
        max_chars = getattr(Config, 'MAX_TEXT_LENGTH_FOR_ANALYSIS', 1500)
        
        if len(cleaned_text) > max_chars:
            logger.info(f"Text lung ({len(cleaned_text)} chars) pentru TinyLlama, trunchiez la {max_chars}")
            
            # TrunchiazƒÉ la o propozi»õie completƒÉ
            truncate_pos = max_chars
            for i in range(max_chars - 200, max_chars):
                if i < len(cleaned_text) and cleaned_text[i] in '.!?':
                    truncate_pos = i + 1
                    break
            
            cleaned_text = cleaned_text[:truncate_pos].strip()
            if not cleaned_text.endswith(('.', '!', '?')):
                cleaned_text += "."
            
            logger.info(f"Text trunchiat la {len(cleaned_text)} caractere pentru TinyLlama")
        
        return cleaned_text
    
    def _tinyllama_only_analysis(self, text, title=None):
        """AnalizƒÉ doar cu TinyLlama (prompturi foarte simple)"""
        prompt = self._create_simple_tinyllama_prompt(text, title)
        
        try:
            start_time = time.time()
            
            response = self.model_handler.generate_response(
                prompt,
                max_new_tokens=200,  # RƒÉspuns scurt pentru TinyLlama
                temperature=0.7,
                do_sample=True
            )
            
            generation_time = time.time() - start_time
            
            logger.info(f"=== TINYLLAMA RƒÇSPUNS ===")
            logger.info(f"Timp: {generation_time:.1f}s")
            logger.info(f"Content: {response[:150]}...")
            logger.info(f"=== SF√ÇR»òIT ===")
            
            parsed_result = self._parse_tinyllama_response(response)
            parsed_result['analysis_type'] = 'tinyllama_only'
            parsed_result['generation_time'] = f"{generation_time:.1f}s"
            
            return parsed_result
            
        except Exception as e:
            logger.error(f"Eroare TinyLlama: {e}")
            return {
                "factuality_score": 5,
                "confidence": 3,
                "reasoning": f"Eroare TinyLlama: {str(e)[:100]}...",
                "questionable_claims": [],
                "analysis_type": "tinyllama_error",
                "error": str(e)
            }
    
    def _hybrid_analysis_tinyllama(self, text, title=None):
        """AnalizƒÉ hibridƒÉ: TinyLlama + Web Search"""
        logger.info("üöÄ Pornesc analizƒÉ hibridƒÉ cu TinyLlama...")
        
        # 1. AnalizƒÉ ini»õialƒÉ cu TinyLlama
        tinyllama_result = self._tinyllama_only_analysis(text, title)
        
        # 2. Web search pentru verificare
        if self.web_search_agent:
            try:
                # Extrage afirma»õii simple pentru verificare
                claims_to_verify = self._extract_simple_claims(text)
                logger.info(f"üìã Verific {len(claims_to_verify)} afirma»õii cu web search")
                
                verified_claims = []
                web_confidence_boost = 0
                
                # 3. VerificƒÉ maxim 3 afirma»õii
                for claim in claims_to_verify[:3]:
                    logger.info(f"üîç Verific: {claim[:50]}...")
                    verification = self.web_search_agent.verify_claim_with_search(claim)
                    verified_claims.append(verification)
                    
                    # AjusteazƒÉ √Æncrederea
                    if verification['verification_status'] == 'adevarata':
                        web_confidence_boost += 1
                    elif verification['verification_status'] == 'falsa':
                        web_confidence_boost -= 2
                
                # 4. CombinƒÉ rezultatele
                final_score = tinyllama_result['factuality_score']
                
                # AjusteazƒÉ scorul bazat pe web search
                if verified_claims:
                    web_adjustment = min(2, max(-3, web_confidence_boost))
                    final_score = max(1, min(10, final_score + web_adjustment))
                
                # √émbunƒÉtƒÉ»õe»ôte √Æncrederea cu web search
                final_confidence = min(10, tinyllama_result['confidence'] + (2 if verified_claims else 0))
                
                # Reasoning √ÆmbunƒÉtƒÉ»õit
                enhanced_reasoning = tinyllama_result['reasoning']
                if verified_claims:
                    true_count = sum(1 for v in verified_claims if v['verification_status'] == 'adevarata')
                    false_count = sum(1 for v in verified_claims if v['verification_status'] == 'falsa')
                    enhanced_reasoning += f"\n\nüîç Verificare web: {len(verified_claims)} afirma»õii. "
                    enhanced_reasoning += f"‚úÖ {true_count} confirmate, ‚ùå {false_count} infirmate."
                
                return {
                    "factuality_score": final_score,
                    "confidence": final_confidence,
                    "reasoning": enhanced_reasoning,
                    "questionable_claims": tinyllama_result['questionable_claims'],
                    "verified_claims": verified_claims,
                    "analysis_type": "hybrid_tinyllama",
                    "web_search_performed": True,
                    "sources_consulted": len(set([url for v in verified_claims for url in v.get('sources_used', [])]))
                }
                
            except Exception as e:
                logger.error(f"Eroare web search: {e}")
                tinyllama_result['analysis_type'] = 'tinyllama_only_web_failed'
                tinyllama_result['web_search_error'] = str(e)
                return tinyllama_result
        
        # Fallback la TinyLlama only
        tinyllama_result['analysis_type'] = 'tinyllama_only'
        return tinyllama_result
    
    def _create_simple_tinyllama_prompt(self, text, title=None):
        """Prompt FOARTE SIMPLU »ôi STRICT pentru TinyLlama sƒÉ rƒÉspundƒÉ JSON"""
        title_text = f"Titlu: {title}\n" if title else ""
        
        # Prompt FOARTE STRICT pentru JSON - for»õƒÉm formatul
        prompt = f"""<|user|>
AnalizeazƒÉ urmƒÉtorul text »ôi spune dacƒÉ este adevƒÉrat sau fals.

{title_text}Text: "{text}"

IMPORTANT: RƒÉspunde DOAR √Æn format JSON dupa modelul urmƒÉtor, fƒÉrƒÉ alte cuvinte:

{{
    "factuality_score": 3,
    "confidence": 8,
    "reasoning": "explica»õia ta aici",
    "questionable_claims": ["problemƒÉ gƒÉsitƒÉ"]
}}

Unde scorul este categorizat: 1-3=fals, 4-6=mixt, 7-10=adevƒÉrat, 
la reasoning pui explicatia ta si la questionable_claims pui ce crezi ca este incorect sau problematic

JSON:
<|assistant|>
{{"""
        
        return prompt
    
    def _parse_tinyllama_response(self, response):
        """ParseazƒÉ rƒÉspunsul TinyLlama cu focus pe JSON for»õat"""
        try:
            logger.info(f"Parsez rƒÉspuns TinyLlama: {response[:100]}...")
            
            # 1. √éncearcƒÉ sƒÉ gƒÉseascƒÉ JSON complet cu {{ la √Ænceput
            # CautƒÉ pattern-ul for»õat cu "factuality_score"
            json_pattern = r'(\{[^{}]*"factuality_score"[^{}]*\})'
            match = re.search(json_pattern, response, re.IGNORECASE | re.DOTALL)
            
            if match:
                json_str = match.group(1)
                logger.info(f"GƒÉsit JSON candidat: {json_str}")
                
                # CurƒÉ»õƒÉ »ôi completeazƒÉ JSON-ul
                json_str = self._fix_incomplete_json(json_str)
                
                try:
                    result = json.loads(json_str)
                    logger.info("‚úÖ JSON parsat cu succes!")
                    return self._validate_result(result)
                except json.JSONDecodeError as e:
                    logger.warning(f"JSON invalid: {e}")
            
            # 2. √éncearcƒÉ sƒÉ construiascƒÉ JSON din bucƒÉ»õi
            constructed_json = self._construct_json_from_response(response)
            if constructed_json:
                try:
                    result = json.loads(constructed_json)
                    logger.info("‚úÖ JSON construit cu succes din bucƒÉ»õi!")
                    return self._validate_result(result)
                except json.JSONDecodeError:
                    pass
            
            # 3. Parsare simplƒÉ (format vechi)
            simple_format = self._parse_simple_format(response)
            if simple_format:
                logger.info("‚úÖ Format simplu parsat")
                return simple_format
            
            # 4. Extrage numere din text
            numbers_format = self._extract_numbers_from_text(response)
            if numbers_format:
                logger.info("‚úÖ Numere extrase din text")
                return numbers_format
            
            # 5. Fallback inteligent
            logger.warning("‚ö†Ô∏è Folosesc fallback inteligent")
            return self._smart_fallback_response(response)
            
        except Exception as e:
            logger.error(f"Eroare criticƒÉ la parsing: {e}")
            return self._emergency_fallback_response(response)
    
    def _fix_incomplete_json(self, json_str):
        """ReparƒÉ JSON incomplet de la TinyLlama"""
        # CurƒÉ»õƒÉ caracterele problematice
        json_str = json_str.strip()
        
        # AsigurƒÉ-te cƒÉ se terminƒÉ cu }
        if not json_str.endswith('}'):
            json_str += '}'
        
        # ReparƒÉ ghilimelele lipsƒÉ
        json_str = re.sub(r'(\w+):', r'"\1":', json_str)
        json_str = re.sub(r':\s*([^",\[\]{}]+)([,}])', r': "\1"\2', json_str)
        
        # ReparƒÉ array-urile
        json_str = re.sub(r'\[([^\[\]]*)\]', lambda m: '["' + m.group(1).replace(',', '","') + '"]', json_str)
        
        return json_str
    
    def _construct_json_from_response(self, response):
        """Construie»ôte JSON din bucƒÉ»õi gƒÉsite √Æn rƒÉspuns"""
        try:
            # CautƒÉ componentele JSON √Æn rƒÉspuns
            score_match = re.search(r'(?:factuality_score|scor)["\s:]*(\d+)', response, re.IGNORECASE)
            confidence_match = re.search(r'(?:confidence|√Æncredere)["\s:]*(\d+)', response, re.IGNORECASE)
            
            # CautƒÉ reasoning/explica»õie
            reasoning_patterns = [
                r'(?:reasoning|explica»õie)["\s:]*"([^"]*)"',
                r'(?:reasoning|explica»õie)["\s:]*(.*?)(?:,|\}|$)',
                r'(PƒÉm√¢ntul.*?\.|.*?fals.*?\.|.*?adevƒÉrat.*?\.)'
            ]
            
            reasoning = "AnalizƒÉ TinyLlama completatƒÉ"
            for pattern in reasoning_patterns:
                match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)
                if match:
                    reasoning = match.group(1).strip().strip('"')
                    break
            
            # Construie»ôte JSON-ul
            if score_match:
                score = int(score_match.group(1))
                confidence = int(confidence_match.group(1)) if confidence_match else 5
                
                # Pentru "The earth is flat" - for»õeazƒÉ scor mic
                if 'flat' in response.lower() and 'earth' in response.lower():
                    if score > 5:  # DacƒÉ TinyLlama a dat scor mare pentru pƒÉm√¢nt plat
                        score = 2  # CorecteazƒÉ la scor mic
                        reasoning = "Afirma»õia cƒÉ PƒÉm√¢ntul este plat este falsƒÉ »ôtiin»õific. " + reasoning
                
                constructed = {
                    "factuality_score": score,
                    "confidence": confidence, 
                    "reasoning": reasoning,
                    "questionable_claims": ["Afirma»õia despre pƒÉm√¢ntul plat"] if 'flat' in response.lower() else []
                }
                
                return json.dumps(constructed)
        except:
            pass
        
        return None
    
    def _smart_fallback_response(self, original_response):
        """Fallback inteligent care √Æn»õelege contextul"""
        response_lower = original_response.lower()
        
        # Detectare specialƒÉ pentru afirma»õii »ôtiin»õific false
        scientific_false_indicators = ['flat earth', 'pƒÉm√¢ntul plat', 'flat', 'plat']
        is_scientific_false = any(indicator in response_lower for indicator in scientific_false_indicators)
        
        if is_scientific_false:
            # Pentru afirma»õii »ôtiin»õific false, for»õeazƒÉ scor mic
            return {
                "factuality_score": 2,
                "confidence": 8,
                "reasoning": "Afirma»õia cƒÉ PƒÉm√¢ntul este plat este falsƒÉ »ôtiin»õific. ExistƒÉ dovezi concrete cƒÉ PƒÉm√¢ntul este sferic.",
                "questionable_claims": ["Teoria pƒÉm√¢ntului plat este contrazisƒÉ de eviden»õe »ôtiin»õifice"]
            }
        
        # AnalizƒÉ sentiment pentru alte cazuri
        positive_words = ['adevƒÉrat', 'corect', 'exact', 'credibil', 'confirmat']
        negative_words = ['fals', 'gre»ôit', 'incorect', 'dubios', 'problemƒÉ', 'false']
        
        positive_count = sum(1 for word in positive_words if word in response_lower)
        negative_count = sum(1 for word in negative_words if word in response_lower)
        
        if negative_count > positive_count:
            score = 3
            confidence = 6
        elif positive_count > negative_count:
            score = 7
            confidence = 6
        else:
            score = 5
            confidence = 4
        
        return {
            "factuality_score": score,
            "confidence": confidence,
            "reasoning": f"AnalizƒÉ TinyLlama: {original_response[:200]}...",
            "questionable_claims": []
        }
    
    def _emergency_fallback_response(self, original_response):
        """Fallback de urgen»õƒÉ"""
        return {
            "factuality_score": 5,
            "confidence": 3,
            "reasoning": "Eroare la procesarea rƒÉspunsului TinyLlama. Text analizat cu succes par»õial.",
            "questionable_claims": []
        }
    
    def _parse_simple_format(self, response):
        """ParseazƒÉ format simplu: Scor: X, √éncredere: Y"""
        try:
            score_match = re.search(r'scor:?\s*(\d+)', response, re.IGNORECASE)
            confidence_match = re.search(r'√Æncredere:?\s*(\d+)', response, re.IGNORECASE)
            
            if score_match:
                score = int(score_match.group(1))
                confidence = int(confidence_match.group(1)) if confidence_match else 5
                
                # Extrage explica»õia
                explanation_patterns = [
                    r'explica»õie:?\s*([^.]*\.)',
                    r'de ce:?\s*([^.]*\.)',
                    r'pentru cƒÉ:?\s*([^.]*\.)'
                ]
                
                reasoning = "AnalizƒÉ TinyLlama"
                for pattern in explanation_patterns:
                    match = re.search(pattern, response, re.IGNORECASE)
                    if match:
                        reasoning = match.group(1).strip()
                        break
                
                # Extrage probleme
                problems = []
                problem_patterns = [
                    r'probleme?:?\s*([^.]*\.)',
                    r'fals:?\s*([^.]*\.)',
                    r'dubios:?\s*([^.]*\.)'
                ]
                
                for pattern in problem_patterns:
                    match = re.search(pattern, response, re.IGNORECASE)
                    if match:
                        problems.append(match.group(1).strip())
                
                return {
                    "factuality_score": max(1, min(10, score)),
                    "confidence": max(1, min(10, confidence)),
                    "reasoning": reasoning,
                    "questionable_claims": problems
                }
        except:
            pass
        
        return None
    
    def _extract_numbers_from_text(self, response):
        """Extrage numere din text c√¢nd formatul nu e clar"""
        numbers = re.findall(r'\b([1-9]|10)\b', response)
        
        if len(numbers) >= 2:
            # Presupune cƒÉ primele douƒÉ numere sunt scorul »ôi √Æncrederea
            score = int(numbers[0])
            confidence = int(numbers[1])
            
            # √éncearcƒÉ sƒÉ gƒÉseascƒÉ un ra»õionament
            sentences = re.split(r'[.!?]', response)
            reasoning = "AnalizƒÉ TinyLlama completatƒÉ"
            
            for sentence in sentences:
                if len(sentence.strip()) > 20:  # Propozi»õie substan»õialƒÉ
                    reasoning = sentence.strip()
                    break
            
            return {
                "factuality_score": max(1, min(10, score)),
                "confidence": max(1, min(10, confidence)),
                "reasoning": reasoning[:200] + "..." if len(reasoning) > 200 else reasoning,
                "questionable_claims": []
            }
        
        return None
    
    def _extract_simple_claims(self, text):
        """Extrage afirma»õii simple pentru web search"""
        # Pentru TinyLlama, pƒÉstrƒÉm simplu - √Æmparte textul √Æn propozi»õii
        sentences = re.split(r'[.!?]', text)
        
        claims = []
        for sentence in sentences:
            sentence = sentence.strip()
            # PƒÉstreazƒÉ propozi»õiile care par sƒÉ facƒÉ afirma»õii
            if (len(sentence) > 15 and 
                len(sentence) < 200 and
                any(word in sentence.lower() for word in ['este', 'sunt', 'a fost', 'au fost', 'va fi', 'vor fi'])):
                claims.append(sentence)
        
        return claims[:5]  # Maxim 5 afirma»õii
    
    def _clean_json_string(self, json_str):
        """CurƒÉ»õƒÉ JSON pentru TinyLlama"""
        # EliminƒÉ comentarii »ôi caractere problematice
        json_str = re.sub(r'//.*', '', json_str)
        json_str = re.sub(r'/\*[\s\S]*?\*/', '', json_str)
        
        # √énlocuie»ôte ghilimelele simple
        json_str = re.sub(r"'([^']*)':", r'"\1":', json_str)
        json_str = re.sub(r":\s*'([^']*)'", r': "\1"', json_str)
        
        # EliminƒÉ virgulele finale
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        return json_str.strip()
    
    def _validate_result(self, result):
        """ValideazƒÉ »ôi completeazƒÉ rezultatul"""
        defaults = {
            "factuality_score": 5,
            "confidence": 5,
            "reasoning": "AnalizƒÉ TinyLlama completatƒÉ",
            "questionable_claims": []
        }
        
        for key, default_value in defaults.items():
            if key not in result:
                result[key] = default_value
        
        # ValideazƒÉ scorurile
        try:
            result["factuality_score"] = max(1, min(10, int(float(result["factuality_score"]))))
            result["confidence"] = max(1, min(10, int(float(result["confidence"]))))
        except (ValueError, TypeError):
            result["factuality_score"] = 5
            result["confidence"] = 5
        
        # LimiteazƒÉ lungimea
        if isinstance(result["reasoning"], str) and len(result["reasoning"]) > 300:
            result["reasoning"] = result["reasoning"][:300] + "..."
        
        if not isinstance(result["questionable_claims"], list):
            result["questionable_claims"] = []
        
        return result
    
    def _fallback_tinyllama_response(self, original_response):
        """Fallback c√¢nd TinyLlama nu poate fi parsat"""
        # AnalizeazƒÉ sentiment-ul rƒÉspunsului
        response_lower = original_response.lower()
        
        # CautƒÉ indicatori pozitivi/negativi
        positive_words = ['adevƒÉrat', 'corect', 'exact', 'credibil', 'bun']
        negative_words = ['fals', 'gre»ôit', 'incorect', 'dubios', 'problemƒÉ']
        
        positive_count = sum(1 for word in positive_words if word in response_lower)
        negative_count = sum(1 for word in negative_words if word in response_lower)
        
        if negative_count > positive_count:
            score = 3
        elif positive_count > negative_count:
            score = 7
        else:
            score = 5
        
        return {
            "factuality_score": score,
            "confidence": 4,
            "reasoning": f"AnalizƒÉ TinyLlama: {original_response[:150]}...",
            "questionable_claims": []
        }